{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.arff as arff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (40%) Correctly implement the ID3 decision tree algorithm, including the ability to handle unknown attributes (You do not need to handle real valued attributes).  \n",
    "### Code Requirements/Notes:\n",
    "- Use standard information gain as your basic attribute evaluation metric.  (Note that normal ID3 would usually augment information gain with gain ratio or some other mechanism to penalize statistically insignificant attribute splits.) \n",
    "- You are welcome to create other classes and/or functions in addition to the ones provided below. (e.g. If you build out a tree structure, you might create a node class).\n",
    "- It is a good idea to use a simple data set (like the lenses data or the pizza homework), which you can check by hand, to test your algorithm to make sure that it is working correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseEstimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13824\\2827129361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mDTClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mClassifierMixin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpurity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \"\"\" Initialize class with chosen hyperparameters.\n\u001b[0;32m      5\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BaseEstimator' is not defined"
     ]
    }
   ],
   "source": [
    "class DTClassifier(BaseEstimator,ClassifierMixin):\n",
    "\n",
    "    def __init__(self,counts=None, max_depth=np.inf, purity=None):\n",
    "        \"\"\" Initialize class with chosen hyperparameters.\n",
    "        Args:\n",
    "        Optional Args (Args we think will make your life easier):\n",
    "            counts: A list of Ints that tell you how many types of each feature there are\n",
    "        Example:\n",
    "            DT  = DTClassifier()\n",
    "            or\n",
    "            DT = DTClassifier(count = [2,3,2,2])\n",
    "            Dataset = \n",
    "            [[0,1,0,0],\n",
    "            [1,2,1,1],\n",
    "            [0,1,1,0],\n",
    "            [1,2,0,1],\n",
    "            [0,0,1,1]]\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.counts = counts\n",
    "        self.max_depth = max_depth\n",
    "        self.purity = purity\n",
    "        \n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit the data; Make the Decision tree\n",
    "\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "            y (array-like): A 1D numpy array with the training targets\n",
    "\n",
    "        Returns:\n",
    "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
    "\n",
    "        \"\"\"\n",
    "        X = numpy.copy(X)\n",
    "        \n",
    "        \"\"\"Goes and substitutes the ? or any other symbol that its not a number\"\"\"\n",
    "        \n",
    "        self.tree = self.split(X,y,0)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def split(self,X,y,deph):\n",
    "    \n",
    "        \"\"\"Go through the depth and check if the tree is pure \"\"\"\n",
    "        \n",
    "        if depth >= self.max_depth or depth >= X.shape[1]:\n",
    "           \n",
    "            return label(y)\n",
    "        \"\"\"subsets is a dict\n",
    "        attribute is the index of chosen attribute (column index of 2-d array X)\"\"\"\n",
    "        subsets, attribute = self.decision(X, y)\n",
    "        values = list(subsets.keys())\n",
    "        tree = {attribute: {values[i]: [None, subsets[values[i]][0].shape[0]/X.shape[0]] for i in range(len(values))}}\n",
    "        for i in range(len(values)):\n",
    "            value = values[i]\n",
    "            new_X, new_y = subsets[value]\n",
    "            # makes the tree and cheks each note:\n",
    "            tree[attribute][value][0] = self.split(new_X, new_y, depth+1)\n",
    "        return tree\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\"\"\"    \n",
    "    def label(self,y):\n",
    "        \"\"\"Get the count of the labels\"\"\"\n",
    "        values, counts = np.unique(y, return_counts = True)\n",
    "        return value[counts.argmax()]\n",
    "        \n",
    "       \n",
    "                \n",
    "       \n",
    "\n",
    "    def decision(self, X, y):\n",
    "        \"\"\"\n",
    "        Here is where we make the decision for the nodes using Entrypy and Information Gain\n",
    "        \"\"\"\n",
    "        label_instance = X.shape[0]\n",
    "        num_attribute = X.shape[1]\n",
    "        #info_gain\n",
    "        \"\"\"Here we get the arrays of the attributes\n",
    "           The way i calculate the Entropy is the we will calculate the \n",
    "           Entopy of each attribute in the dateset\n",
    "        \"\"\"\n",
    "        attribute_array = np.zeros(num_attribute)\n",
    "        \n",
    "        \n",
    "        #intrinsic_info = np.zeros(num_attribute)\n",
    "        #entropy calculation\n",
    "        #prev_info\n",
    "        total_entropy = self.entropy_attribute_calculation(y)\n",
    "        for i in range(num_attribute):\n",
    "            after_entropy_calculation = 0\n",
    "            \"\"\"\n",
    "            split with attribute. Get the Values for the Gain of the last Column\n",
    "            and the current attribute\n",
    "            \"\"\"\n",
    "            group = self.group_with_attribute(X, y, i)\n",
    "            for value in group:\n",
    "                after_entropy_calculation += group[value][1].shape[0] / label_instance * self.log2_operation(group[value][1])\n",
    "            gain[i] = total_entropy - after_entropy_calculation\n",
    "            #Make sure that its greater than 0 \n",
    "            #numpy.nan_to_num\n",
    "            #dont have to be grater to zero\n",
    "            denominator[i] = max(self.log2_operation, 0.001)\n",
    "        \"\"\"\"\n",
    "        gain = gain * (gain > gain.mean())\n",
    "        gain = gain/denominator\n",
    "            # intrinsic_info\n",
    "        \"\"\"\n",
    "        attribute = gain.argmax()\n",
    "\n",
    "        #,attribute \n",
    "        return self.group_with_attribute(X, y, attribute)\n",
    "    \n",
    "    def log2_operation(self,group):\n",
    "        addition = np.array([group[i][1].shape[0] for i in group])\n",
    "        addition = np.nan_to_num(addition/addition.sum())\n",
    "        total = -np.dot(addition, np.log2(addition))\n",
    "        return total\n",
    "        \n",
    "    \n",
    "    def group_with_attribute(self,X, y, attribute):\n",
    "        \"\"\"\n",
    "        mask\n",
    "        loop for \n",
    "        mask = X[:,index] == unique_value\n",
    "        grouped_data = X[mask:,] \n",
    "        \"\"\"\n",
    "        label_instance = X.shape[0]\n",
    "        values = list(set(X[:, attribute]))\n",
    "        mask = X[:,index]\n",
    "        subsets = [[[], []] for i in range(len(values))]\n",
    "        for i in range(len(values)):\n",
    "            mask = X[:,index] == values[i]\n",
    "            subsets[num_subset][0].append(X[mask,:])\n",
    "            subsets[num_subset][1].append(y[mask,:])\n",
    "\n",
    "        return {values[i]: subsets[i] for i in range(len(values))}\n",
    "        \n",
    "    \n",
    "    \n",
    "    def entropy_attribute_calculation(self,y):\n",
    "        unique_cols, cols_count = np.unique(y,return_counts = True)\n",
    "        label_instance = y.shape[0]\n",
    "        addition = np.array([cols_count[i]/label_instance for i in cols_count])\n",
    "        total = -np.dot(addition, np.log2(addition))\n",
    "        return -np.dot(total, np.log2(total))\n",
    "    \n",
    "  \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict all classes for a dataset X\n",
    "\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "\n",
    "        Returns:\n",
    "            array, shape (n_samples,)\n",
    "                Predicted target values per element in X.\n",
    "        \"\"\"\n",
    "        X = np.copy(X)\n",
    "        return np.round(y)\n",
    "\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\" Return accuracy(Classification Acc) of model on a given dataset. Must implement own score function.\n",
    "\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with data, excluding targets\n",
    "            y (array-like): A 1D numpy array of the targets \n",
    "        \"\"\"\n",
    "        output = self.predict(X)\n",
    "        if y.shape[1] == 1:\n",
    "            accuracy = (output == y).mean()\n",
    "        return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Debug\n",
    "\n",
    "Debug your model by training on the lenses dataset: [Debug Dataset (lenses.arff)](https://byu.instructure.com/courses/14142/files?preview=4622251)\n",
    "\n",
    "Test your model on the lenses test set: [Debug Test Dataset (lenses_test.arff)](https://byu.instructure.com/courses/14142/files?preview=4622254)\n",
    "\n",
    "Parameters:\n",
    "(optional) counts = [3,2,2,2] (You should compute this when you read in the data, before fitting)\n",
    "\n",
    "---\n",
    "\n",
    "Expected Results: Accuracy = [0.33]\n",
    "\n",
    "Predictions should match this file: [Lenses Predictions (pred_lenses.csv)](https://byu.instructure.com/courses/14142/files?preview=4622260)\n",
    "\n",
    "*NOTE: The [Lenses Prediction (pred_lenses.csv)](https://byu.instructure.com/courses/14142/files?preview=4622260) uses the following encoding: soft=2, hard=0, none=1. If your encoding is different, then your output will be different, but not necessarily incorrect.*\n",
    "\n",
    "Split Information Gains (These do not need to be in this exact order):\n",
    "\n",
    "[0.5487949406953987, 0.7704260414863775, 0.3166890883150208, 1.0, 0.4591479170272447, 0.9182958340544894]\n",
    "\n",
    "<!-- You should be able to get about 68% (61%-82%) predictive accuracy on the lenses data -->\n",
    "\n",
    "Here's what your decision tree splits should look like, and the corresponding child node predictions:\n",
    "\n",
    "Decision Tree:\n",
    "<pre>\n",
    "tear_prod_rate = normal:\n",
    "    astigmatism = no:\n",
    "        age = pre_presbyopic:\n",
    "            prediction: soft\n",
    "        age = presbyopic:\n",
    "            spectacle_prescrip = hypermetrope:\n",
    "                prediction: soft\n",
    "            spectacle_prescrip = myope:\n",
    "                prediction: none\n",
    "        age = young:\n",
    "            prediction: soft\n",
    "    astigmatism = yes:\n",
    "        spectacle_prescrip = hypermetrope:\n",
    "            age = pre_presbyopic:\n",
    "                prediction: none\n",
    "            age = presbyopic:\n",
    "                prediction: none\n",
    "            age = young:\n",
    "                prediction: hard\n",
    "        spectacle_prescrip = myope:\n",
    "            prediction: hard\n",
    "tear_prod_rate = reduced:\n",
    "    prediction: none\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load debug training data \n",
    "\n",
    "\n",
    "# Train Decision Tree\n",
    "\n",
    "\n",
    "# Load debug test data\n",
    "\n",
    "\n",
    "# Predict and compute model accuracy\n",
    "\n",
    "\n",
    "# Print the information gain of every split you make.\n",
    "mat, meta = arff.loa\n",
    "wdarff('datasets/lenses.arff')\n",
    "mat = mat.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional/Additional Debugging Dataset - Pizza Homework\n",
    "# pizza_dataset = np.array([[1,2,0],[0,0,0],[0,1,1],[1,1,1],[1,0,0],[1,0,1],[0,2,1],[1,0,0],[0,2,0]])\n",
    "# pizza_labels = np.array([2,0,1,2,1,2,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Evaluation\n",
    "\n",
    "We will evaluate your model based on its performance on the zoo dataset. \n",
    "\n",
    "Train your model using this dataset: [Evaluation Train Dataset (zoo.arff)](https://byu.instructure.com/courses/14142/files?preview=4622270)\n",
    "\n",
    "Test your model on this dataset: [Evaluation Test Dataset (zoo_test.arff)](https://byu.instructure.com/courses/14142/files?preview=4622274)\n",
    "\n",
    "Parameters:\n",
    "(optional) counts = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 2, 2] (You should compute this when you read in the data, before fitting)\n",
    "\n",
    "---\n",
    "Print out your accuracy on the evaluation test dataset.\n",
    "\n",
    "Print out the information gain of every split you make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation training data\n",
    "\n",
    "\n",
    "# Train Decision Tree\n",
    "\n",
    "\n",
    "# Load evaluation test data\n",
    "\n",
    "\n",
    "# Print out the information gain for every split you make\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (20%) You will use your ID3 algorithm to induce decision trees for the cars dataset and the voting dataset.  Do not use a stopping criterion, but induce the tree as far as it can go (until classes are pure or there are no more data or attributes to split on).  \n",
    "- Implement and use 10-fold Cross Validation (CV) on each data set to predict how well the models will do on novel data.  \n",
    "- For each dataset, report the training and test classification accuracy for each fold and the average test accuracy. \n",
    "- As a rough sanity check, typical decision tree accuracies for these data sets are: Cars: .90-.95, Vote: .92-.95."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Implement 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that implements 10-fold cross validation\n",
    "\n",
    "data = cross_validation.KFold(len(train_set), n_folds=10, indices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.2 Cars Dataset\n",
    "- Use this [Cars Dataset (cars.arff)](hhttps://byu.instructure.com/courses/14142/files?preview=4622293)\n",
    "- Make a table for your k-fold cross validation accuracies\n",
    "\n",
    "*If you are having trouble using scipy's loadarff function (scipy.io.arff.loadarff), try:*\n",
    "\n",
    "*pip install arff &nbsp;&nbsp;&nbsp;&nbsp;          # Install arff library*\n",
    "\n",
    "*import arff as arf*                   \n",
    "\n",
    "*cars = list(arf.load('cars.arff'))   &nbsp;&nbsp;&nbsp;&nbsp;# Load your downloaded dataset (!curl, etc.)*\n",
    "\n",
    "*df = pd.DataFrame(cars)*  \n",
    "\n",
    "*There may be additional cleaning needed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 10-fold CV on Cars Dataset\n",
    "import pandas as pd\n",
    "data = pd.read_csv('datasets/cars.arff')\n",
    "\n",
    "\n",
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values.reshape(-1,1)\n",
    "data = cross_validation.KFold(len(train_set), n_folds=10, indices=False)\n",
    "\n",
    "# Report Training and Test Classification Accuracies\n",
    "\n",
    "# Report Average Test Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Voting Dataset\n",
    "- Use this [Voting Dataset with missing values (voting_with_missing.arff)](https://byu.instructure.com/courses/14142/files?preview=4622298)\n",
    "- Note that you will need to support unknown attributes in the voting data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    handicapped-infants water-project-cost-sharing  \\\n",
      "0                  b'n'                       b'y'   \n",
      "1                  b'n'                       b'y'   \n",
      "2                  b'?'                       b'y'   \n",
      "3                  b'n'                       b'y'   \n",
      "4                  b'y'                       b'y'   \n",
      "..                  ...                        ...   \n",
      "430                b'n'                       b'n'   \n",
      "431                b'n'                       b'n'   \n",
      "432                b'n'                       b'?'   \n",
      "433                b'n'                       b'n'   \n",
      "434                b'n'                       b'y'   \n",
      "\n",
      "    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n",
      "0                                b'n'                 b'y'            b'y'   \n",
      "1                                b'n'                 b'y'            b'y'   \n",
      "2                                b'y'                 b'?'            b'y'   \n",
      "3                                b'y'                 b'n'            b'?'   \n",
      "4                                b'y'                 b'n'            b'y'   \n",
      "..                                ...                  ...             ...   \n",
      "430                              b'y'                 b'y'            b'y'   \n",
      "431                              b'y'                 b'n'            b'n'   \n",
      "432                              b'n'                 b'y'            b'y'   \n",
      "433                              b'n'                 b'y'            b'y'   \n",
      "434                              b'n'                 b'y'            b'y'   \n",
      "\n",
      "    religious-groups-in-schools anti-satellite-test-ban  \\\n",
      "0                          b'y'                    b'n'   \n",
      "1                          b'y'                    b'n'   \n",
      "2                          b'y'                    b'n'   \n",
      "3                          b'y'                    b'n'   \n",
      "4                          b'y'                    b'n'   \n",
      "..                          ...                     ...   \n",
      "430                        b'y'                    b'n'   \n",
      "431                        b'n'                    b'y'   \n",
      "432                        b'y'                    b'n'   \n",
      "433                        b'y'                    b'?'   \n",
      "434                        b'y'                    b'n'   \n",
      "\n",
      "    aid-to-nicaraguan-contras mx-missile immigration  \\\n",
      "0                        b'n'       b'n'        b'y'   \n",
      "1                        b'n'       b'n'        b'n'   \n",
      "2                        b'n'       b'n'        b'n'   \n",
      "3                        b'n'       b'n'        b'n'   \n",
      "4                        b'n'       b'n'        b'n'   \n",
      "..                        ...        ...         ...   \n",
      "430                      b'n'       b'y'        b'y'   \n",
      "431                      b'y'       b'y'        b'y'   \n",
      "432                      b'n'       b'n'        b'n'   \n",
      "433                      b'?'       b'?'        b'?'   \n",
      "434                      b'n'       b'n'        b'y'   \n",
      "\n",
      "    synfuels-corporation-cutback education-spending superfund-right-to-sue  \\\n",
      "0                           b'?'               b'y'                   b'y'   \n",
      "1                           b'n'               b'y'                   b'y'   \n",
      "2                           b'y'               b'n'                   b'y'   \n",
      "3                           b'y'               b'n'                   b'y'   \n",
      "4                           b'y'               b'?'                   b'y'   \n",
      "..                           ...                ...                    ...   \n",
      "430                         b'n'               b'y'                   b'y'   \n",
      "431                         b'n'               b'n'                   b'n'   \n",
      "432                         b'y'               b'y'                   b'y'   \n",
      "433                         b'n'               b'y'                   b'y'   \n",
      "434                         b'n'               b'y'                   b'y'   \n",
      "\n",
      "    crime duty-free-exports export-administration-act-south-africa  \\\n",
      "0    b'y'              b'n'                                   b'y'   \n",
      "1    b'y'              b'n'                                   b'?'   \n",
      "2    b'y'              b'n'                                   b'n'   \n",
      "3    b'n'              b'n'                                   b'y'   \n",
      "4    b'y'              b'y'                                   b'y'   \n",
      "..    ...               ...                                    ...   \n",
      "430  b'y'              b'n'                                   b'y'   \n",
      "431  b'n'              b'n'                                   b'y'   \n",
      "432  b'y'              b'n'                                   b'y'   \n",
      "433  b'y'              b'n'                                   b'y'   \n",
      "434  b'y'              b'?'                                   b'n'   \n",
      "\n",
      "             Class  \n",
      "0    b'republican'  \n",
      "1    b'republican'  \n",
      "2      b'democrat'  \n",
      "3      b'democrat'  \n",
      "4      b'democrat'  \n",
      "..             ...  \n",
      "430  b'republican'  \n",
      "431    b'democrat'  \n",
      "432  b'republican'  \n",
      "433  b'republican'  \n",
      "434  b'republican'  \n",
      "\n",
      "[435 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# Used 10-fold CV on Voting Dataset\n",
    "from scipy.io import arff\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "data = arff.loadarff((r\"C:\\Users\\BYU Rental\\Desktop\\voting_with_missing (1).arff\"))\n",
    "df = pd.DataFrame(data[0])\n",
    "X = df.copy()\n",
    "print(df)\n",
    "\n",
    "# Report Training and Test Classification Accuracies\n",
    "\n",
    "# Report Average Test Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Discuss Your Results\n",
    "\n",
    "- Summarize your results from both datasets, and discuss what you observed. \n",
    "- A fully expanded tree will often get 100% accuracy on the training set. Why does this happen and in what cases might it not? A: A fully expanded tree will often get 100% accuracy because we could be using a part of training data for test. If our tranning and test dataset are the same the we will produce the correct results every time.It is not 100% when we have them seperated. The accuracy of the model will change when it handles unknown values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (15%) For each of the two problems above, summarize in English what the decision tree has learned (i.e., look at the induced tree and describe what rules it has discovered to try to solve each task). \n",
    "- If the tree is very large you can just discuss a few of the more shallow attribute combinations and the most important decisions made high in the tree. A:A decision tree uses a devide and conquer stratagy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Discuss what the decision tree induced on the cars dataset has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree has learned that going recursively through an algorithm lead to a leaf node. Where a tree was formed. The nodes will corresponde to an attribute from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Discuss what the decision tree induced on the voting dataset has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree has learned that going recursively through an algorithm lead to a leaf node. Where a tree was formed.The nodes will corresponde to an attribute from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 How did you handle unknown attributes in the voting problem? Why did you choose this approach? (Do not use the approach of just throwing out data with unknown attributes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the np.unique wich allowed me to hanlde unknown varibale as a frquency to which they appeared. Using that frequency I was able to calculate the Entropy of the attributes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 (10%) Use Scikit Learn's decision tree on the voting dataset and compare your results. Try different parameters and report what parameters perform best on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 sklearn on Voting Dataset\n",
    "- Use this [Voting Dataset with missing values (voting_with_missing.arff)](https://byu.instructure.com/courses/14142/files?preview=4622298)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    handicapped-infants water-project-cost-sharing  \\\n",
      "0                  b'n'                       b'y'   \n",
      "1                  b'n'                       b'y'   \n",
      "2                  b'?'                       b'y'   \n",
      "3                  b'n'                       b'y'   \n",
      "4                  b'y'                       b'y'   \n",
      "..                  ...                        ...   \n",
      "430                b'n'                       b'n'   \n",
      "431                b'n'                       b'n'   \n",
      "432                b'n'                       b'?'   \n",
      "433                b'n'                       b'n'   \n",
      "434                b'n'                       b'y'   \n",
      "\n",
      "    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n",
      "0                                b'n'                 b'y'            b'y'   \n",
      "1                                b'n'                 b'y'            b'y'   \n",
      "2                                b'y'                 b'?'            b'y'   \n",
      "3                                b'y'                 b'n'            b'?'   \n",
      "4                                b'y'                 b'n'            b'y'   \n",
      "..                                ...                  ...             ...   \n",
      "430                              b'y'                 b'y'            b'y'   \n",
      "431                              b'y'                 b'n'            b'n'   \n",
      "432                              b'n'                 b'y'            b'y'   \n",
      "433                              b'n'                 b'y'            b'y'   \n",
      "434                              b'n'                 b'y'            b'y'   \n",
      "\n",
      "    religious-groups-in-schools anti-satellite-test-ban  \\\n",
      "0                          b'y'                    b'n'   \n",
      "1                          b'y'                    b'n'   \n",
      "2                          b'y'                    b'n'   \n",
      "3                          b'y'                    b'n'   \n",
      "4                          b'y'                    b'n'   \n",
      "..                          ...                     ...   \n",
      "430                        b'y'                    b'n'   \n",
      "431                        b'n'                    b'y'   \n",
      "432                        b'y'                    b'n'   \n",
      "433                        b'y'                    b'?'   \n",
      "434                        b'y'                    b'n'   \n",
      "\n",
      "    aid-to-nicaraguan-contras mx-missile immigration  \\\n",
      "0                        b'n'       b'n'        b'y'   \n",
      "1                        b'n'       b'n'        b'n'   \n",
      "2                        b'n'       b'n'        b'n'   \n",
      "3                        b'n'       b'n'        b'n'   \n",
      "4                        b'n'       b'n'        b'n'   \n",
      "..                        ...        ...         ...   \n",
      "430                      b'n'       b'y'        b'y'   \n",
      "431                      b'y'       b'y'        b'y'   \n",
      "432                      b'n'       b'n'        b'n'   \n",
      "433                      b'?'       b'?'        b'?'   \n",
      "434                      b'n'       b'n'        b'y'   \n",
      "\n",
      "    synfuels-corporation-cutback education-spending superfund-right-to-sue  \\\n",
      "0                           b'?'               b'y'                   b'y'   \n",
      "1                           b'n'               b'y'                   b'y'   \n",
      "2                           b'y'               b'n'                   b'y'   \n",
      "3                           b'y'               b'n'                   b'y'   \n",
      "4                           b'y'               b'?'                   b'y'   \n",
      "..                           ...                ...                    ...   \n",
      "430                         b'n'               b'y'                   b'y'   \n",
      "431                         b'n'               b'n'                   b'n'   \n",
      "432                         b'y'               b'y'                   b'y'   \n",
      "433                         b'n'               b'y'                   b'y'   \n",
      "434                         b'n'               b'y'                   b'y'   \n",
      "\n",
      "    crime duty-free-exports export-administration-act-south-africa  \\\n",
      "0    b'y'              b'n'                                   b'y'   \n",
      "1    b'y'              b'n'                                   b'?'   \n",
      "2    b'y'              b'n'                                   b'n'   \n",
      "3    b'n'              b'n'                                   b'y'   \n",
      "4    b'y'              b'y'                                   b'y'   \n",
      "..    ...               ...                                    ...   \n",
      "430  b'y'              b'n'                                   b'y'   \n",
      "431  b'n'              b'n'                                   b'y'   \n",
      "432  b'y'              b'n'                                   b'y'   \n",
      "433  b'y'              b'n'                                   b'y'   \n",
      "434  b'y'              b'?'                                   b'n'   \n",
      "\n",
      "             Class  \n",
      "0    b'republican'  \n",
      "1    b'republican'  \n",
      "2      b'democrat'  \n",
      "3      b'democrat'  \n",
      "4      b'democrat'  \n",
      "..             ...  \n",
      "430  b'republican'  \n",
      "431    b'democrat'  \n",
      "432  b'republican'  \n",
      "433  b'republican'  \n",
      "434  b'republican'  \n",
      "\n",
      "[435 rows x 17 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: b'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12428\\602626114.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;31m# Explore different parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    935\u001b[0m         \"\"\"\n\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[0mcheck_X_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m             X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    166\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             )\n",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    576\u001b[0m                 \u001b[1;31m# :(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2066\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: b'y'"
     ]
    }
   ],
   "source": [
    "# Use sklearn's Decision Tree to learn the voting dataset\n",
    "from scipy.io import arff\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "data = arff.loadarff(r\"C:\\Users\\BYU Rental\\Desktop\\voting_with_missing (1).arff\")\n",
    "df = pd.DataFrame(data[0])\n",
    "X = df.copy()\n",
    "print(df)\n",
    "y = data['target']\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "# Explore different parameters\n",
    "tree.plot_tree(clf)\n",
    "# Report results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss results & compare to your method's results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 (10%) Choose a data set of your choice (not already used in this or previous labs) and use the sklearn decision tree to learn it. Experiment with different hyper-parameters to try to get the best results possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    handicapped-infants water-project-cost-sharing  \\\n",
      "0                  b'n'                       b'y'   \n",
      "1                  b'n'                       b'y'   \n",
      "2                  b'?'                       b'y'   \n",
      "3                  b'n'                       b'y'   \n",
      "4                  b'y'                       b'y'   \n",
      "..                  ...                        ...   \n",
      "430                b'n'                       b'n'   \n",
      "431                b'n'                       b'n'   \n",
      "432                b'n'                       b'?'   \n",
      "433                b'n'                       b'n'   \n",
      "434                b'n'                       b'y'   \n",
      "\n",
      "    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n",
      "0                                b'n'                 b'y'            b'y'   \n",
      "1                                b'n'                 b'y'            b'y'   \n",
      "2                                b'y'                 b'?'            b'y'   \n",
      "3                                b'y'                 b'n'            b'?'   \n",
      "4                                b'y'                 b'n'            b'y'   \n",
      "..                                ...                  ...             ...   \n",
      "430                              b'y'                 b'y'            b'y'   \n",
      "431                              b'y'                 b'n'            b'n'   \n",
      "432                              b'n'                 b'y'            b'y'   \n",
      "433                              b'n'                 b'y'            b'y'   \n",
      "434                              b'n'                 b'y'            b'y'   \n",
      "\n",
      "    religious-groups-in-schools anti-satellite-test-ban  \\\n",
      "0                          b'y'                    b'n'   \n",
      "1                          b'y'                    b'n'   \n",
      "2                          b'y'                    b'n'   \n",
      "3                          b'y'                    b'n'   \n",
      "4                          b'y'                    b'n'   \n",
      "..                          ...                     ...   \n",
      "430                        b'y'                    b'n'   \n",
      "431                        b'n'                    b'y'   \n",
      "432                        b'y'                    b'n'   \n",
      "433                        b'y'                    b'?'   \n",
      "434                        b'y'                    b'n'   \n",
      "\n",
      "    aid-to-nicaraguan-contras mx-missile immigration  \\\n",
      "0                        b'n'       b'n'        b'y'   \n",
      "1                        b'n'       b'n'        b'n'   \n",
      "2                        b'n'       b'n'        b'n'   \n",
      "3                        b'n'       b'n'        b'n'   \n",
      "4                        b'n'       b'n'        b'n'   \n",
      "..                        ...        ...         ...   \n",
      "430                      b'n'       b'y'        b'y'   \n",
      "431                      b'y'       b'y'        b'y'   \n",
      "432                      b'n'       b'n'        b'n'   \n",
      "433                      b'?'       b'?'        b'?'   \n",
      "434                      b'n'       b'n'        b'y'   \n",
      "\n",
      "    synfuels-corporation-cutback education-spending superfund-right-to-sue  \\\n",
      "0                           b'?'               b'y'                   b'y'   \n",
      "1                           b'n'               b'y'                   b'y'   \n",
      "2                           b'y'               b'n'                   b'y'   \n",
      "3                           b'y'               b'n'                   b'y'   \n",
      "4                           b'y'               b'?'                   b'y'   \n",
      "..                           ...                ...                    ...   \n",
      "430                         b'n'               b'y'                   b'y'   \n",
      "431                         b'n'               b'n'                   b'n'   \n",
      "432                         b'y'               b'y'                   b'y'   \n",
      "433                         b'n'               b'y'                   b'y'   \n",
      "434                         b'n'               b'y'                   b'y'   \n",
      "\n",
      "    crime duty-free-exports export-administration-act-south-africa  \\\n",
      "0    b'y'              b'n'                                   b'y'   \n",
      "1    b'y'              b'n'                                   b'?'   \n",
      "2    b'y'              b'n'                                   b'n'   \n",
      "3    b'n'              b'n'                                   b'y'   \n",
      "4    b'y'              b'y'                                   b'y'   \n",
      "..    ...               ...                                    ...   \n",
      "430  b'y'              b'n'                                   b'y'   \n",
      "431  b'n'              b'n'                                   b'y'   \n",
      "432  b'y'              b'n'                                   b'y'   \n",
      "433  b'y'              b'n'                                   b'y'   \n",
      "434  b'y'              b'?'                                   b'n'   \n",
      "\n",
      "             Class  \n",
      "0    b'republican'  \n",
      "1    b'republican'  \n",
      "2      b'democrat'  \n",
      "3      b'democrat'  \n",
      "4      b'democrat'  \n",
      "..             ...  \n",
      "430  b'republican'  \n",
      "431    b'democrat'  \n",
      "432  b'republican'  \n",
      "433  b'republican'  \n",
      "434  b'republican'  \n",
      "\n",
      "[435 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn's Decision Tree on a new dataset\n",
    "from scipy.io import arff\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(df)\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "tree.plot_tree(clf)\n",
    "\n",
    "# Experiment with different hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (5%) Visualize sklearn's decision tree for your chosen data set (using export_graphviz or another tool) and discuss what you find. If your tree is too deep to reasonably fit on one page, show only the first few levels (e.g., top 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include decision tree visualization here\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph = graphviz.Source(dot_data) \n",
    "# Discuss what the model has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (optional 5% extra credit) Implement reduced error pruning to help avoid overfitting.  \n",
    "- You will need to take a validation set out of your training data to do this, while still having a test set to test your final accuracy. \n",
    "- Create a table comparing your decision tree implementation's results on the cars and voting data sets with and without reduced error pruning. \n",
    "- This table should compare:\n",
    "    - a) The # of nodes (including leaf nodes) and tree depth of the final decision trees \n",
    "    - b) The generalization (test set) accuracy. (For the unpruned 10-fold CV models, just use their average values in the table)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
